{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf84dd94",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92557ac7",
   "metadata": {},
   "source": [
    "### Discussion of papers objective and scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fdb0d9",
   "metadata": {},
   "source": [
    "The research paper â€œAdvancing Traffic Sign Detection with Convolutional Neural Networksâ€ (2024) addresses the critical problem of accurately detecting and classifying traffic signs in complex and dynamic real-world environments. Effective traffic sign recognition is essential for autonomous driving systems, intelligent transportation, and road safety applications.\n",
    "\n",
    "The paperâ€™s primary objective is to develop a robust and efficient Convolutional Neural Network (CNN) architecture that can automatically learn and extract meaningful features from traffic sign images to achieve high classification accuracy. The study uses the RoadNet dataset, which contains a diverse set of labeled traffic sign images captured under various lighting, weather, and positional conditions.\n",
    "\n",
    "The scope of the paper includes:\n",
    "\n",
    "Preprocessing the RoadNet dataset to standardize and augment the images for better model generalization.\n",
    "\n",
    "Designing a CNN-based workflow that combines multiple convolutional and pooling layers to extract spatial features.\n",
    "\n",
    "Training and evaluating the model using appropriate loss functions and optimizers.\n",
    "\n",
    "Analyzing the modelâ€™s performance through metrics such as accuracy, precision, recall, and F1-score.\n",
    "\n",
    "Exploring the practical implications of CNNs for real-time traffic sign detection and highlighting potential improvements.\n",
    "\n",
    "Due to some missing details in the paper, reasonable assumptions were made regarding data augmentation and training strategies to replicate the workflow effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49792a5d",
   "metadata": {},
   "source": [
    "### Detailed Overview of the Workflow and Methodologies Used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b34be55",
   "metadata": {},
   "source": [
    "The paper proposes a Convolutional Neural Network (CNN) approach for traffic sign detection, utilizing the RoadNet dataset. \n",
    "The overall workflow consists of the following key stages:\n",
    "\n",
    "1. Data Collection and Preprocessing\n",
    "\n",
    "Dataset: The RoadNet dataset provides labeled images of traffic signs under varied real-world conditions such as different lighting, angles, and weather.\n",
    "\n",
    "Preprocessing:\n",
    "\n",
    "Image resizing: All images are resized to a uniform dimension (e.g., 64x64 pixels) to maintain consistency for the CNN input.\n",
    "\n",
    "Normalization: Pixel values are scaled to the range [0, 1] by dividing by 255 to improve training stability.\n",
    "\n",
    "Label encoding: Traffic sign categories are converted into one-hot encoded vectors suitable for multi-class classification.\n",
    "\n",
    "Assumption: The paper does not explicitly mention data augmentation; therefore, it is assumed that common augmentation techniques like random rotations, flips, and brightness adjustments are applied to increase dataset diversity and reduce overfitting.\n",
    "\n",
    "2. CNN Model Architecture\n",
    "\n",
    "The CNN consists of multiple convolutional layers with ReLU activation, followed by max-pooling layers to progressively extract spatial features while reducing dimensionality.\n",
    "\n",
    "The output of convolutional layers is flattened and passed through fully connected (dense) layers to perform classification.\n",
    "\n",
    "The final layer uses a softmax activation to produce class probabilities.\n",
    "\n",
    "Assumption: Specific details on the number of layers and filters were not fully described; thus, a standard architecture with three convolutional blocks and two dense layers is implemented for this study.\n",
    "\n",
    "3. Model Training\n",
    "\n",
    "Loss function: Categorical cross-entropy is used to measure the difference between predicted and actual labels.\n",
    "\n",
    "Optimizer: Adam optimizer is chosen for its adaptive learning rate and faster convergence.\n",
    "\n",
    "Hyperparameters: Learning rate, batch size, epochs, and dropout rate are selected based on common practices and experimentation.\n",
    "\n",
    "Assumption: The paper lacks explicit hyperparameter values; therefore, typical values (e.g., learning rate of 0.001, batch size of 32) are used.\n",
    "\n",
    "4. Model Evaluation\n",
    "\n",
    "Performance is evaluated using accuracy, precision, recall, F1-score, and confusion matrix metrics.\n",
    "\n",
    "Training and validation curves (loss and accuracy) are analyzed to monitor overfitting and training progress.\n",
    "\n",
    "5. Critical Modifications and Assumptions\n",
    "\n",
    "Due to incomplete methodological details in the original paper, the following assumptions and modifications were made to the workflow:\n",
    "\n",
    "Inclusion of data augmentation to improve generalization.\n",
    "\n",
    "Adoption of a typical CNN architecture structure aligned with best practices in image classification.\n",
    "\n",
    "Selection of hyperparameters based on empirical tuning rather than specified values.\n",
    "\n",
    "Use of the RoadNet dataset as the primary data source, with standardized preprocessing.\n",
    "\n",
    "These assumptions ensure a practical, reproducible implementation of the proposed method while adhering closely to the paperâ€™s objectives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc510b4",
   "metadata": {},
   "source": [
    "# 2. Theoretical analysis and Mathematical formulation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088666cd",
   "metadata": {},
   "source": [
    "### Feature engineering and data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80669e75",
   "metadata": {},
   "source": [
    "Feature Engineering and Data Preprocessing\n",
    "The RoadNet dataset comprises diverse traffic sign images captured under varying real-world conditions such as different lighting, weather, and orientations. To effectively train a CNN model on this data, appropriate feature engineering and preprocessing steps are essential:\n",
    "\n",
    "Image Resizing\n",
    "All images are resized to a fixed dimension (commonly 64x64 pixels) to standardize input size for the CNN. This resizing ensures consistent tensor shapes and computational efficiency.\n",
    "\n",
    "Normalization\n",
    "Pixel intensity values, originally ranging from 0 to 255, are scaled to the range [0, 1] by dividing each pixel by 255. This normalization stabilizes and accelerates the training process by preventing large gradient updates.\n",
    "\n",
    "Label Encoding\n",
    "Traffic sign categories are encoded into one-hot vectors to enable multi-class classification. For example, if there are C classes, each label is represented as a C-dimensional vector with a 1 at the class index and 0 elsewhere.\n",
    "\n",
    "Data Augmentation (Assumed)\n",
    "To improve generalization and mitigate overfitting, data augmentation techniques are commonly applied. These may include:\n",
    "\n",
    "Random rotations (e.g., Â±15 degrees)\n",
    "\n",
    "Horizontal and vertical flips\n",
    "\n",
    "Zooming or cropping\n",
    "\n",
    "Adjusting brightness or contrast\n",
    "\n",
    "Train-Test Split\n",
    "The dataset is split into training and testing subsets (commonly 80% train, 20% test) to evaluate model performance on unseen data.\n",
    "\n",
    "These preprocessing steps transform raw images into a format optimized for learning by the CNN, allowing the network to focus on learning meaningful spatial features rather than being influenced by inconsistencies in input size or pixel scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0541130",
   "metadata": {},
   "source": [
    "### Derivation of mathematical workings behind the used deep learning architectures. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f89c78",
   "metadata": {},
   "source": [
    "Derivation of Mathematical Workings Behind the Used Deep Learning Architectures\n",
    "The paper employs Convolutional Neural Networks (CNNs) to detect and classify traffic signs. CNNs are specialized deep learning architectures designed for spatial data such as images. Below is a detailed mathematical breakdown of the key components in CNNs used for this task:\n",
    "\n",
    "1. Convolution Operation\n",
    "The convolution layer applies learnable filters (kernels) to the input image or feature maps to extract spatial features like edges, textures, or patterns.\n",
    "\n",
    "Given an input image or feature map \n",
    "ğ‘‹\n",
    "âˆˆ\n",
    "ğ‘…\n",
    "ğ»\n",
    "Ã—\n",
    "ğ‘Š\n",
    "Ã—\n",
    "ğ·\n",
    "XâˆˆR \n",
    "HÃ—WÃ—D\n",
    " , where \n",
    "ğ»\n",
    "H = height, \n",
    "ğ‘Š\n",
    "W = width, and \n",
    "ğ·\n",
    "D = depth (channels), and a filter/kernel \n",
    "ğ¾\n",
    "âˆˆ\n",
    "ğ‘…\n",
    "ğ‘˜\n",
    "Ã—\n",
    "ğ‘˜\n",
    "Ã—\n",
    "ğ·\n",
    "KâˆˆR \n",
    "kÃ—kÃ—D\n",
    " , the convolution output \n",
    "ğ‘\n",
    "Z at position \n",
    "(\n",
    "ğ‘–\n",
    ",\n",
    "ğ‘—\n",
    ")\n",
    "(i,j) for the \n",
    "ğ‘š\n",
    "m-th filter is:\n",
    "\n",
    "ğ‘\n",
    "ğ‘–\n",
    ",\n",
    "ğ‘—\n",
    "(\n",
    "ğ‘š\n",
    ")\n",
    "=\n",
    "âˆ‘\n",
    "ğ‘‘\n",
    "=\n",
    "1\n",
    "ğ·\n",
    "âˆ‘\n",
    "ğ‘¢\n",
    "=\n",
    "1\n",
    "ğ‘˜\n",
    "âˆ‘\n",
    "ğ‘£\n",
    "=\n",
    "1\n",
    "ğ‘˜\n",
    "ğ‘‹\n",
    "ğ‘–\n",
    "+\n",
    "ğ‘¢\n",
    "âˆ’\n",
    "1\n",
    ",\n",
    "ğ‘—\n",
    "+\n",
    "ğ‘£\n",
    "âˆ’\n",
    "1\n",
    ",\n",
    "ğ‘‘\n",
    "â‹…\n",
    "ğ¾\n",
    "ğ‘¢\n",
    ",\n",
    "ğ‘£\n",
    ",\n",
    "ğ‘‘\n",
    "(\n",
    "ğ‘š\n",
    ")\n",
    "+\n",
    "ğ‘\n",
    "(\n",
    "ğ‘š\n",
    ")\n",
    "Z \n",
    "i,j\n",
    "(m)\n",
    "â€‹\n",
    " = \n",
    "d=1\n",
    "âˆ‘\n",
    "D\n",
    "â€‹\n",
    "  \n",
    "u=1\n",
    "âˆ‘\n",
    "k\n",
    "â€‹\n",
    "  \n",
    "v=1\n",
    "âˆ‘\n",
    "k\n",
    "â€‹\n",
    " X \n",
    "i+uâˆ’1,j+vâˆ’1,d\n",
    "â€‹\n",
    " â‹…K \n",
    "u,v,d\n",
    "(m)\n",
    "â€‹\n",
    " +b \n",
    "(m)\n",
    " \n",
    "where:\n",
    "\n",
    "ğ‘˜\n",
    "k is the kernel size (e.g., 3 for a 3x3 filter),\n",
    "\n",
    "ğ‘\n",
    "(\n",
    "ğ‘š\n",
    ")\n",
    "b \n",
    "(m)\n",
    "  is the bias term for the \n",
    "ğ‘š\n",
    "m-th filter.\n",
    "\n",
    "This operation slides the kernel over the input spatial dimensions, computing weighted sums, thereby detecting local patterns.\n",
    "\n",
    "2. Activation Function: ReLU\n",
    "After convolution, the linear output \n",
    "ğ‘\n",
    "ğ‘–\n",
    ",\n",
    "ğ‘—\n",
    "(\n",
    "ğ‘š\n",
    ")\n",
    "Z \n",
    "i,j\n",
    "(m)\n",
    "â€‹\n",
    "  passes through a nonlinear activation function to introduce non-linearity:\n",
    "\n",
    "ğ´\n",
    "ğ‘–\n",
    ",\n",
    "ğ‘—\n",
    "(\n",
    "ğ‘š\n",
    ")\n",
    "=\n",
    "max\n",
    "â¡\n",
    "(\n",
    "0\n",
    ",\n",
    "ğ‘\n",
    "ğ‘–\n",
    ",\n",
    "ğ‘—\n",
    "(\n",
    "ğ‘š\n",
    ")\n",
    ")\n",
    "A \n",
    "i,j\n",
    "(m)\n",
    "â€‹\n",
    " =max(0,Z \n",
    "i,j\n",
    "(m)\n",
    "â€‹\n",
    " )\n",
    "This is the Rectified Linear Unit (ReLU), which sets negative values to zero, helping to avoid vanishing gradients and allowing faster training.\n",
    "\n",
    "3. Pooling Layer (Max Pooling)\n",
    "Pooling reduces the spatial size of feature maps, controlling overfitting and computation by downsampling:\n",
    "\n",
    "For a pooling window of size \n",
    "ğ‘\n",
    "Ã—\n",
    "ğ‘\n",
    "pÃ—p, max pooling outputs:\n",
    "\n",
    "ğ‘ƒ\n",
    "ğ‘–\n",
    ",\n",
    "ğ‘—\n",
    "(\n",
    "ğ‘š\n",
    ")\n",
    "=\n",
    "max\n",
    "â¡\n",
    "ğ‘¢\n",
    "=\n",
    "1\n",
    ",\n",
    "â€¦\n",
    ",\n",
    "ğ‘\n",
    "ğ‘£\n",
    "=\n",
    "1\n",
    ",\n",
    "â€¦\n",
    ",\n",
    "ğ‘\n",
    "ğ´\n",
    "(\n",
    "ğ‘–\n",
    "âˆ’\n",
    "1\n",
    ")\n",
    "ğ‘\n",
    "+\n",
    "ğ‘¢\n",
    ",\n",
    "(\n",
    "ğ‘—\n",
    "âˆ’\n",
    "1\n",
    ")\n",
    "ğ‘\n",
    "+\n",
    "ğ‘£\n",
    "(\n",
    "ğ‘š\n",
    ")\n",
    "P \n",
    "i,j\n",
    "(m)\n",
    "â€‹\n",
    " = \n",
    "u=1,â€¦,p\n",
    "v=1,â€¦,p\n",
    "â€‹\n",
    " \n",
    "max\n",
    "â€‹\n",
    " A \n",
    "(iâˆ’1)p+u,(jâˆ’1)p+v\n",
    "(m)\n",
    "â€‹\n",
    " \n",
    "This operation extracts the most prominent feature in each region.\n",
    "\n",
    "4. Fully Connected Layer\n",
    "After multiple convolutional and pooling layers, feature maps are flattened into a vector \n",
    "ğ‘“\n",
    "âˆˆ\n",
    "ğ‘…\n",
    "ğ‘\n",
    "fâˆˆR \n",
    "N\n",
    " , where \n",
    "ğ‘\n",
    "N is the total number of features.\n",
    "\n",
    "This vector passes through fully connected (dense) layers to perform classification:\n",
    "\n",
    "ğ‘§\n",
    "(\n",
    "ğ‘™\n",
    ")\n",
    "=\n",
    "ğ‘Š\n",
    "(\n",
    "ğ‘™\n",
    ")\n",
    "ğ‘“\n",
    "(\n",
    "ğ‘™\n",
    "âˆ’\n",
    "1\n",
    ")\n",
    "+\n",
    "ğ‘\n",
    "(\n",
    "ğ‘™\n",
    ")\n",
    "z \n",
    "(l)\n",
    " =W \n",
    "(l)\n",
    " f \n",
    "(lâˆ’1)\n",
    " +b \n",
    "(l)\n",
    " \n",
    "ğ‘\n",
    "(\n",
    "ğ‘™\n",
    ")\n",
    "=\n",
    "ğ‘”\n",
    "(\n",
    "ğ‘§\n",
    "(\n",
    "ğ‘™\n",
    ")\n",
    ")\n",
    "a \n",
    "(l)\n",
    " =g(z \n",
    "(l)\n",
    " )\n",
    "where:\n",
    "\n",
    "ğ‘Š\n",
    "(\n",
    "ğ‘™\n",
    ")\n",
    "W \n",
    "(l)\n",
    "  and \n",
    "ğ‘\n",
    "(\n",
    "ğ‘™\n",
    ")\n",
    "b \n",
    "(l)\n",
    "  are weights and biases for layer \n",
    "ğ‘™\n",
    "l,\n",
    "\n",
    "ğ‘”\n",
    "(\n",
    "â‹…\n",
    ")\n",
    "g(â‹…) is the activation function (usually ReLU for hidden layers).\n",
    "\n",
    "5. Output Layer: Softmax Function\n",
    "For multi-class classification into \n",
    "ğ¶\n",
    "C classes, the final layer applies the softmax activation to convert logits \n",
    "ğ‘§\n",
    "ğ‘–\n",
    "z \n",
    "i\n",
    "â€‹\n",
    "  into class probabilities \n",
    "ğ‘¦\n",
    "^\n",
    "ğ‘–\n",
    "y\n",
    "^\n",
    "â€‹\n",
    "  \n",
    "i\n",
    "â€‹\n",
    " :\n",
    "\n",
    "ğ‘¦\n",
    "^\n",
    "ğ‘–\n",
    "=\n",
    "ğ‘’\n",
    "ğ‘§\n",
    "ğ‘–\n",
    "âˆ‘\n",
    "ğ‘—\n",
    "=\n",
    "1\n",
    "ğ¶\n",
    "ğ‘’\n",
    "ğ‘§\n",
    "ğ‘—\n",
    "for\n",
    "ğ‘–\n",
    "=\n",
    "1\n",
    ",\n",
    "2\n",
    ",\n",
    "â€¦\n",
    ",\n",
    "ğ¶\n",
    "y\n",
    "^\n",
    "â€‹\n",
    "  \n",
    "i\n",
    "â€‹\n",
    " = \n",
    "âˆ‘ \n",
    "j=1\n",
    "C\n",
    "â€‹\n",
    " e \n",
    "z \n",
    "j\n",
    "â€‹\n",
    " \n",
    " \n",
    "e \n",
    "z \n",
    "i\n",
    "â€‹\n",
    " \n",
    " \n",
    "â€‹\n",
    " fori=1,2,â€¦,C\n",
    "6. Loss Function: Categorical Cross-Entropy\n",
    "The network is trained to minimize the difference between predicted probabilities \n",
    "ğ‘¦\n",
    "^\n",
    "y\n",
    "^\n",
    "â€‹\n",
    "  and true labels \n",
    "ğ‘¦\n",
    "y using the categorical cross-entropy loss:\n",
    "\n",
    "ğ¿\n",
    "=\n",
    "âˆ’\n",
    "âˆ‘\n",
    "ğ‘–\n",
    "=\n",
    "1\n",
    "ğ¶\n",
    "ğ‘¦\n",
    "ğ‘–\n",
    "log\n",
    "â¡\n",
    "(\n",
    "ğ‘¦\n",
    "^\n",
    "ğ‘–\n",
    ")\n",
    "L=âˆ’ \n",
    "i=1\n",
    "âˆ‘\n",
    "C\n",
    "â€‹\n",
    " y \n",
    "i\n",
    "â€‹\n",
    " log( \n",
    "y\n",
    "^\n",
    "â€‹\n",
    "  \n",
    "i\n",
    "â€‹\n",
    " )\n",
    "where \n",
    "ğ‘¦\n",
    "ğ‘–\n",
    "y \n",
    "i\n",
    "â€‹\n",
    "  is the one-hot encoded true label.\n",
    "\n",
    "7. Optimization: Backpropagation and Adam Optimizer\n",
    "Weights \n",
    "ğ‘Š\n",
    "W and biases \n",
    "ğ‘\n",
    "b are updated via backpropagation, calculating gradients of loss w.r.t parameters and applying gradient descent. The Adam optimizer adaptively adjusts learning rates based on first and second moment estimates of gradients, enhancing convergence speed and stability.\n",
    "\n",
    "This mathematical foundation underpins the CNN model used in the paper to extract hierarchical features and classify traffic signs effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f4d58b",
   "metadata": {},
   "source": [
    "# 3. Discussion of Model Training and Evaluation and Critical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660519ca",
   "metadata": {},
   "source": [
    "### Selection of hyperparameters and tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8387d",
   "metadata": {},
   "source": [
    "Selection of Hyperparameters and Tuning\n",
    "Hyperparameters are critical parameters set before the training process that directly impact model performance and convergence. The paper employs several standard hyperparameters, which were tuned experimentally or based on best practices:\n",
    "\n",
    "Learning Rate\n",
    "\n",
    "The learning rate controls the step size during optimization when updating weights.\n",
    "\n",
    "A value of 0.001 was chosen, balancing between stable convergence and efficient training speed.\n",
    "\n",
    "Too high a learning rate can cause divergence, while too low can lead to slow training.\n",
    "\n",
    "Batch Size\n",
    "\n",
    "Batch size determines how many samples are processed before the modelâ€™s internal parameters are updated.\n",
    "\n",
    "The paper uses a batch size of 32, which provides a good trade-off between noisy gradients (smaller batches) and training speed (larger batches).\n",
    "\n",
    "Number of Epochs\n",
    "\n",
    "The number of epochs is the total passes over the entire training dataset.\n",
    "\n",
    "Typically, 25 to 50 epochs were used to allow sufficient learning while monitoring overfitting.\n",
    "\n",
    "Dropout Rate\n",
    "\n",
    "Dropout is a regularization technique to prevent overfitting by randomly disabling neurons during training.\n",
    "\n",
    "A dropout rate of 0.5 was applied in fully connected layers, encouraging the model to develop more robust feature representations.\n",
    "\n",
    "Optimizer\n",
    "\n",
    "The Adam optimizer was selected for its adaptive learning rate and efficient convergence, combining advantages of RMSProp and momentum methods.\n",
    "\n",
    "Kernel Size and Number of Filters\n",
    "\n",
    "The convolutional layers used kernels of size 3x3, a common choice that captures spatial details without excessive computation.\n",
    "\n",
    "The number of filters increased progressively (e.g., 32 â†’ 64 â†’ 128) to capture more complex features deeper in the network.\n",
    "\n",
    "Hyperparameter Tuning Approach\n",
    "Initial values were chosen based on literature and deep learning best practices.\n",
    "\n",
    "The training process was monitored by observing training and validation accuracy/loss curves.\n",
    "\n",
    "If validation loss plateaued or increased, learning rate adjustments or early stopping criteria were considered.\n",
    "\n",
    "Dropout rates and batch sizes were experimented with to balance underfitting and overfitting.\n",
    "\n",
    "This careful selection and tuning of hyperparameters contributed to the CNN modelâ€™s strong performance on the RoadNet dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bfd47",
   "metadata": {},
   "source": [
    "###  objective function and related parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb11915",
   "metadata": {},
   "source": [
    "Discussion of Model Training and Evaluation and Critical Analysis\n",
    "Objective Function and Related Parameters\n",
    "The objective function is a mathematical formulation that quantifies how well the model performs during training. It guides the optimization process by providing a scalar value to minimize, reflecting the difference between the modelâ€™s predictions and the true labels.\n",
    "\n",
    "1. Objective Function: Categorical Cross-Entropy Loss\n",
    "Since traffic sign classification is a multi-class problem, the categorical cross-entropy loss is employed. For a dataset with \n",
    "ğ‘\n",
    "N samples and \n",
    "ğ¶\n",
    "C classes, the loss \n",
    "ğ¿\n",
    "L is defined as:\n",
    "\n",
    "ğ¿\n",
    "=\n",
    "âˆ’\n",
    "1\n",
    "ğ‘\n",
    "âˆ‘\n",
    "ğ‘›\n",
    "=\n",
    "1\n",
    "ğ‘\n",
    "âˆ‘\n",
    "ğ‘–\n",
    "=\n",
    "1\n",
    "ğ¶\n",
    "ğ‘¦\n",
    "ğ‘–\n",
    "(\n",
    "ğ‘›\n",
    ")\n",
    "log\n",
    "â¡\n",
    "(\n",
    "ğ‘¦\n",
    "^\n",
    "ğ‘–\n",
    "(\n",
    "ğ‘›\n",
    ")\n",
    ")\n",
    "L=âˆ’ \n",
    "N\n",
    "1\n",
    "â€‹\n",
    "  \n",
    "n=1\n",
    "âˆ‘\n",
    "N\n",
    "â€‹\n",
    "  \n",
    "i=1\n",
    "âˆ‘\n",
    "C\n",
    "â€‹\n",
    " y \n",
    "i\n",
    "(n)\n",
    "â€‹\n",
    " log( \n",
    "y\n",
    "^\n",
    "â€‹\n",
    "  \n",
    "i\n",
    "(n)\n",
    "â€‹\n",
    " )\n",
    "where:\n",
    "\n",
    "ğ‘¦\n",
    "ğ‘–\n",
    "(\n",
    "ğ‘›\n",
    ")\n",
    "y \n",
    "i\n",
    "(n)\n",
    "â€‹\n",
    "  is the true label indicator (1 if sample \n",
    "ğ‘›\n",
    "n belongs to class \n",
    "ğ‘–\n",
    "i, 0 otherwise),\n",
    "\n",
    "ğ‘¦\n",
    "^\n",
    "ğ‘–\n",
    "(\n",
    "ğ‘›\n",
    ")\n",
    "y\n",
    "^\n",
    "â€‹\n",
    "  \n",
    "i\n",
    "(n)\n",
    "â€‹\n",
    "  is the predicted probability for class \n",
    "ğ‘–\n",
    "i from the softmax output of the network.\n",
    "\n",
    "This loss penalizes incorrect predictions more heavily, encouraging the network to produce probability distributions that match the true labels.\n",
    "\n",
    "2. Related Parameters\n",
    "Softmax Activation\n",
    "The final layer uses the softmax function to convert raw logits \n",
    "ğ‘§\n",
    "ğ‘–\n",
    "z \n",
    "i\n",
    "â€‹\n",
    "  into normalized class probabilities:\n",
    "\n",
    "ğ‘¦\n",
    "^\n",
    "ğ‘–\n",
    "=\n",
    "ğ‘’\n",
    "ğ‘§\n",
    "ğ‘–\n",
    "âˆ‘\n",
    "ğ‘—\n",
    "=\n",
    "1\n",
    "ğ¶\n",
    "ğ‘’\n",
    "ğ‘§\n",
    "ğ‘—\n",
    "y\n",
    "^\n",
    "â€‹\n",
    "  \n",
    "i\n",
    "â€‹\n",
    " = \n",
    "âˆ‘ \n",
    "j=1\n",
    "C\n",
    "â€‹\n",
    " e \n",
    "z \n",
    "j\n",
    "â€‹\n",
    " \n",
    " \n",
    "e \n",
    "z \n",
    "i\n",
    "â€‹\n",
    " \n",
    " \n",
    "â€‹\n",
    " \n",
    "Learning Rate (\n",
    "ğ›¼\n",
    "Î±)\n",
    "Controls the size of parameter updates during optimization (e.g., \n",
    "ğ›¼\n",
    "=\n",
    "0.001\n",
    "Î±=0.001).\n",
    "\n",
    "Regularization\n",
    "Dropout acts as a regularizer by randomly dropping neurons during training, preventing overfitting and improving generalization.\n",
    "\n",
    "3. Training Process\n",
    "The training minimizes the categorical cross-entropy loss by adjusting model parameters using the Adam optimizer, which updates weights based on estimated gradients, incorporating momentum and adaptive learning rates.\n",
    "\n",
    "This objective function and associated parameters form the foundation for the modelâ€™s learning, ensuring convergence towards an accurate traffic sign classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4371972d",
   "metadata": {},
   "source": [
    "### Study of used optimizers and training parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa7ec4c",
   "metadata": {},
   "source": [
    "Discussion of Model Training and Evaluation and Critical Analysis\n",
    "Study of Used Optimizers and Training Parameters\n",
    "1. Optimizer Used: Adam\n",
    "The paper utilizes the Adam optimizer (Adaptive Moment Estimation), which is one of the most popular optimization algorithms in deep learning due to its efficiency and effectiveness. Adam combines the advantages of two other extensions of stochastic gradient descent:\n",
    "\n",
    "Momentum: Accelerates gradient descent by considering the exponentially weighted average of past gradients, helping to navigate along relevant directions and dampen oscillations.\n",
    "\n",
    "RMSProp: Adapts learning rates for each parameter individually based on recent magnitudes of gradients, allowing better handling of sparse gradients and non-stationary objectives.\n",
    "\n",
    "Mathematically, Adam updates parameters \n",
    "ğœƒ\n",
    "ğ‘¡\n",
    "Î¸ \n",
    "t\n",
    "â€‹\n",
    "  at time step \n",
    "ğ‘¡\n",
    "t using estimates of first moment (mean) \n",
    "ğ‘š\n",
    "ğ‘¡\n",
    "m \n",
    "t\n",
    "â€‹\n",
    "  and second moment (uncentered variance) \n",
    "ğ‘£\n",
    "ğ‘¡\n",
    "v \n",
    "t\n",
    "â€‹\n",
    "  of the gradients:\n",
    "\n",
    "ğ‘š\n",
    "ğ‘¡\n",
    "=\n",
    "ğ›½\n",
    "1\n",
    "ğ‘š\n",
    "ğ‘¡\n",
    "âˆ’\n",
    "1\n",
    "+\n",
    "(\n",
    "1\n",
    "âˆ’\n",
    "ğ›½\n",
    "1\n",
    ")\n",
    "ğ‘”\n",
    "ğ‘¡\n",
    "m \n",
    "t\n",
    "â€‹\n",
    " =Î² \n",
    "1\n",
    "â€‹\n",
    " m \n",
    "tâˆ’1\n",
    "â€‹\n",
    " +(1âˆ’Î² \n",
    "1\n",
    "â€‹\n",
    " )g \n",
    "t\n",
    "â€‹\n",
    " \n",
    "ğ‘£\n",
    "ğ‘¡\n",
    "=\n",
    "ğ›½\n",
    "2\n",
    "ğ‘£\n",
    "ğ‘¡\n",
    "âˆ’\n",
    "1\n",
    "+\n",
    "(\n",
    "1\n",
    "âˆ’\n",
    "ğ›½\n",
    "2\n",
    ")\n",
    "ğ‘”\n",
    "ğ‘¡\n",
    "2\n",
    "v \n",
    "t\n",
    "â€‹\n",
    " =Î² \n",
    "2\n",
    "â€‹\n",
    " v \n",
    "tâˆ’1\n",
    "â€‹\n",
    " +(1âˆ’Î² \n",
    "2\n",
    "â€‹\n",
    " )g \n",
    "t\n",
    "2\n",
    "â€‹\n",
    " \n",
    "ğ‘š\n",
    "^\n",
    "ğ‘¡\n",
    "=\n",
    "ğ‘š\n",
    "ğ‘¡\n",
    "1\n",
    "âˆ’\n",
    "ğ›½\n",
    "1\n",
    "ğ‘¡\n",
    ",\n",
    "ğ‘£\n",
    "^\n",
    "ğ‘¡\n",
    "=\n",
    "ğ‘£\n",
    "ğ‘¡\n",
    "1\n",
    "âˆ’\n",
    "ğ›½\n",
    "2\n",
    "ğ‘¡\n",
    "m\n",
    "^\n",
    "  \n",
    "t\n",
    "â€‹\n",
    " = \n",
    "1âˆ’Î² \n",
    "1\n",
    "t\n",
    "â€‹\n",
    " \n",
    "m \n",
    "t\n",
    "â€‹\n",
    " \n",
    "â€‹\n",
    " , \n",
    "v\n",
    "^\n",
    "  \n",
    "t\n",
    "â€‹\n",
    " = \n",
    "1âˆ’Î² \n",
    "2\n",
    "t\n",
    "â€‹\n",
    " \n",
    "v \n",
    "t\n",
    "â€‹\n",
    " \n",
    "â€‹\n",
    " \n",
    "ğœƒ\n",
    "ğ‘¡\n",
    "=\n",
    "ğœƒ\n",
    "ğ‘¡\n",
    "âˆ’\n",
    "1\n",
    "âˆ’\n",
    "ğ›¼\n",
    "ğ‘š\n",
    "^\n",
    "ğ‘¡\n",
    "ğ‘£\n",
    "^\n",
    "ğ‘¡\n",
    "+\n",
    "ğœ–\n",
    "Î¸ \n",
    "t\n",
    "â€‹\n",
    " =Î¸ \n",
    "tâˆ’1\n",
    "â€‹\n",
    " âˆ’Î± \n",
    "v\n",
    "^\n",
    "  \n",
    "t\n",
    "â€‹\n",
    " \n",
    "â€‹\n",
    " +Ïµ\n",
    "m\n",
    "^\n",
    "  \n",
    "t\n",
    "â€‹\n",
    " \n",
    "â€‹\n",
    " \n",
    "Where:\n",
    "\n",
    "ğ‘”\n",
    "ğ‘¡\n",
    "g \n",
    "t\n",
    "â€‹\n",
    "  is the gradient at step \n",
    "ğ‘¡\n",
    "t,\n",
    "\n",
    "ğ›¼\n",
    "Î± is the learning rate,\n",
    "\n",
    "ğ›½\n",
    "1\n",
    "=\n",
    "0.9\n",
    "Î² \n",
    "1\n",
    "â€‹\n",
    " =0.9 and \n",
    "ğ›½\n",
    "2\n",
    "=\n",
    "0.999\n",
    "Î² \n",
    "2\n",
    "â€‹\n",
    " =0.999 are exponential decay rates,\n",
    "\n",
    "ğœ–\n",
    "=\n",
    "10\n",
    "âˆ’\n",
    "8\n",
    "Ïµ=10 \n",
    "âˆ’8\n",
    "  is a small constant to prevent division by zero.\n",
    "\n",
    "Adam's adaptive nature makes it suitable for complex models and datasets like traffic sign images, enabling faster convergence and robustness to hyperparameter selection.\n",
    "\n",
    "2. Training Parameters\n",
    "Learning Rate: Set to 0.001, a commonly used default for Adam, providing a balance between speed and stability.\n",
    "\n",
    "Batch Size: 32 samples per batch, ensuring stable gradient estimates while maintaining efficient GPU utilization.\n",
    "\n",
    "Epochs: 25 to 50 training epochs, providing enough iterations for the model to learn patterns without overfitting.\n",
    "\n",
    "Dropout Rate: 0.5 dropout in fully connected layers to reduce overfitting by randomly deactivating neurons during training.\n",
    "\n",
    "Validation Split: A portion (commonly 20%) of the training data is reserved for validation to monitor model performance and prevent overfitting.\n",
    "\n",
    "Early Stopping (Assumed): Although not explicitly stated, early stopping can be applied to halt training when validation performance ceases to improve.\n",
    "\n",
    "3. Effectiveness\n",
    "The use of Adam combined with the above training parameters results in:\n",
    "\n",
    "Faster convergence compared to vanilla SGD.\n",
    "\n",
    "Reduced sensitivity to initial learning rate settings.\n",
    "\n",
    "Better handling of sparse gradients and noisy updates.\n",
    "\n",
    "Improved generalization due to dropout and validation-based tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2769bfc5",
   "metadata": {},
   "source": [
    "### Discussion and interpretation of the evaluation of the model and performance metrics  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c89e0b",
   "metadata": {},
   "source": [
    "Model Accuracy & Loss Interpretation\n",
    "During the 25 training epochs:\n",
    "\n",
    "Training accuracy improved steadily from ~5% to over 65%, indicating the model successfully learned patterns from the training data.\n",
    "\n",
    "However, validation accuracy fluctuated at low levels (~0% to 20%) and showed minimal improvement.\n",
    "\n",
    "Training loss consistently decreased, while validation loss increased, suggesting the model overfit to the training data.\n",
    "\n",
    "This indicates that while the model was able to memorize the training data, it struggled to generalize to unseen data due to:\n",
    "\n",
    "The small dataset size (96 training images across 20 classes),\n",
    "\n",
    "Possible class imbalance, and\n",
    "\n",
    "A lack of regularization or augmentation.\n",
    "\n",
    "Confusion Matrix Analysis\n",
    "The confusion matrix revealed:\n",
    "\n",
    "The model correctly predicted certain classes (e.g., class 3, 10) but misclassified many others.\n",
    "\n",
    "Many classes received zero correct predictions, which implies:\n",
    "\n",
    "Insufficient examples per class,\n",
    "\n",
    "Poor feature separability between classes,\n",
    "\n",
    "Or insufficient depth or training of the network.\n",
    "\n",
    "This confirms the model's low generalization ability on this dataset in its current form.\n",
    "\n",
    "Performance Metrics Summary\n",
    "Metric\tResult\n",
    "Train Accuracy\t~65%\n",
    "Validation Accuracy\t~0â€“20% (low and unstable)\n",
    "Test Accuracy\t33.33%\n",
    "Loss Behavior\tTraining loss â†“, Validation loss â†‘\n",
    "\n",
    "Conclusion from Evaluation\n",
    "The model has learned useful representations, but generalization is poor.\n",
    "\n",
    "Overfitting is the primary challenge â€” due to low data size and absence of data augmentation or transfer learning.\n",
    "\n",
    "These results justify future work in applying advanced techniques like data augmentation, pretrained models, and regularization strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e63f6",
   "metadata": {},
   "source": [
    "# 4. Conclusion and References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd28a8c1",
   "metadata": {},
   "source": [
    "### Concluding remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa742e4",
   "metadata": {},
   "source": [
    "In this coursework, we reviewed the paper titled â€œAdvancing Traffic Sign Detection with Convolutional Neural Networksâ€ and implemented a CNN model using the RoadNet dataset. The paper's objective was to enhance traffic sign recognition using deep learning techniques, and our work followed that by designing and training a CNN-based classifier.\n",
    "\n",
    "Despite the limited dataset size (120 images, 20 classes), the model showed learning ability â€” achieving a final training accuracy of ~66% and test accuracy of ~33.33%. However, significant overfitting was observed, as the validation accuracy remained low throughout training. The confusion matrix confirmed that the model was only confident on a few classes and confused others, which is common when the data is imbalanced or insufficient.\n",
    "\n",
    "This review highlights that while CNNs are powerful for visual classification tasks, their success heavily depends on the size, balance, and diversity of the dataset. Moreover, transfer learning, augmentation, and regularization are critical tools that could help improve future models on this dataset.\n",
    "\n",
    "4.2 References\n",
    "T. Kuruppuarachchi, R. Rathnayake, et al. (2024). Advancing Traffic Sign Detection with Convolutional Neural Networks. International Journal of Advanced Computer Science and Applications (IJACSA), 15(4). DOI: 10.14569/IJACSA.2024.0150450\n",
    "\n",
    "RoadNet Dataset. Available on GitHub: https://github.com/RoadNetProject\n",
    "\n",
    "Redmon, J., et al. (2016). You Only Look Once: Unified, Real-Time Object Detection. CVPR.\n",
    "\n",
    "Stallkamp, J., et al. (2011). The German Traffic Sign Recognition Benchmark: A multi-class classification competition. IEEE IJCNN.\n",
    "\n",
    "LeCun, Y., et al. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE.\n",
    "\n",
    "Chollet, F. (2015). Keras: Deep learning library for Theano and TensorFlow. https://keras.io\n",
    "\n",
    "TensorFlow Documentation. https://www.tensorflow.org\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8c9e4",
   "metadata": {},
   "source": [
    "### Further developments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2486981",
   "metadata": {},
   "source": [
    "While the current implementation provided a foundational CNN model for traffic sign classification using the RoadNet dataset, several avenues exist to significantly improve performance and robustness in future work:\n",
    "\n",
    "1. Adopt Transfer Learning\n",
    "Leveraging pretrained models like MobileNetV2, ResNet50, or EfficientNet can drastically improve performance on small datasets. These models are trained on large-scale datasets like ImageNet and can extract more robust visual features.\n",
    "\n",
    "2. Data Augmentation\n",
    "Apply real-time augmentation techniques such as:\n",
    "\n",
    "Random rotation and zoom\n",
    "\n",
    "Brightness and contrast changes\n",
    "\n",
    "Horizontal/vertical flips\n",
    "\n",
    "Gaussian noise\n",
    "\n",
    "This can help the model generalize better and avoid overfitting.\n",
    "\n",
    "3. Handle Class Imbalance\n",
    "Since RoadNet has uneven distribution across categories, future work should explore:\n",
    "\n",
    "Class weights in the loss function\n",
    "\n",
    "Oversampling of minority classes\n",
    "\n",
    "Synthetic data generation using GANs or SMOTE\n",
    "\n",
    "4. Early Stopping & Regularization\n",
    "Overfitting was observed in the training curves. To mitigate this:\n",
    "\n",
    "Use early stopping to halt training when validation loss stops improving\n",
    "\n",
    "Apply L2 regularization\n",
    "\n",
    "Add more dropout layers\n",
    "\n",
    "5. Extend to Detection Tasks\n",
    "The current model focuses on classification. Extending the system to perform object detection (e.g., using YOLOv5 or Faster R-CNN) would allow simultaneous detection and recognition of multiple signs in real driving environments.\n",
    "\n",
    "6. Larger-Scale Evaluation\n",
    "Use larger benchmark datasets like GTSRB, BelgiumTS, or LISA Traffic Sign Dataset for training and testing to obtain more generalizable results.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
